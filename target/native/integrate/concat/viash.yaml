functionality:
  name: "concat"
  namespace: "integrate"
  version: "main_build"
  authors:
  - name: "Dries Schaumont"
    email: "Dschaumo@its.jnj.com"
    roles:
    - "maintainer"
    props: {}
  inputs: []
  outputs: []
  arguments:
  - type: "file"
    name: "--input"
    alternatives:
    - "-i"
    description: "Paths to the different samples to be concatenated."
    example:
    - "sample_paths"
    default: []
    must_exist: false
    required: true
    direction: "input"
    multiple: true
    multiple_sep: ","
  - type: "string"
    name: "--sample_names"
    alternatives: []
    description: "Names of the different samples that have to be concatenated. Must\
      \ be of same length as `--input`."
    example:
    - "sample_names"
    default: []
    required: true
    choices: []
    direction: "input"
    multiple: true
    multiple_sep: ","
  - type: "file"
    name: "--output"
    alternatives:
    - "-o"
    example:
    - "output.h5mu"
    default: []
    must_exist: false
    required: false
    direction: "output"
    multiple: false
    multiple_sep: ":"
  - type: "string"
    name: "--obs_sample_name"
    alternatives: []
    description: "Name of the .obs key under which to add the sample names."
    example: []
    default:
    - "sample_id"
    required: false
    choices: []
    direction: "input"
    multiple: false
    multiple_sep: ":"
  - type: "string"
    name: "--compression"
    alternatives: []
    description: "The compression format to be used on the final h5mu object."
    example: []
    default:
    - "gzip"
    required: false
    choices: []
    direction: "input"
    multiple: false
    multiple_sep: ":"
  - type: "string"
    name: "--other_axis_mode"
    alternatives: []
    description: "How to handle the merging of other axis (var, obs, ...).\n - None:\
      \ keep no data\n - same: only keep elements of the matrices which are the same\
      \ in each of the samples\n - unique: only keep elements for which there is only\
      \ 1 possible value (1 value that can occur in multiple samples)\n - first: keep\
      \ the annotation from the first sample\n - only: keep elements that show up\
      \ in only one of the objects (1 unique element in only 1 sample)\n - move: identical\
      \ to 'same', but moving the conflicting values to .varm or .obsm\n"
    example: []
    default:
    - "move"
    required: false
    choices:
    - "same"
    - "unique"
    - "first"
    - "only"
    - "concat"
    - "move"
    direction: "input"
    multiple: false
    multiple_sep: ":"
  argument_groups: []
  resources:
  - type: "bash_script"
    text: |
      #!/usr/bin/env bash
      
      # concat main_build
      # 
      # This wrapper script is auto-generated by viash 0.6.0 and is thus a derivative
      # work thereof. This software comes with ABSOLUTELY NO WARRANTY from Data
      # Intuitive.
      # 
      # The component may contain files which fall under a different license. The
      # authors of this component should specify the license in the header of such
      # files, or include a separate license file detailing the licenses of all included
      # files.
      # 
      # Component authors:
      #  * Dries Schaumont <Dschaumo@its.jnj.com> (maintainer)
      
      set -e
      
      if [ -z "$VIASH_TEMP" ]; then
        VIASH_TEMP=${VIASH_TEMP:-$VIASH_TMPDIR}
        VIASH_TEMP=${VIASH_TEMP:-$VIASH_TEMPDIR}
        VIASH_TEMP=${VIASH_TEMP:-$VIASH_TMP}
        VIASH_TEMP=${VIASH_TEMP:-$TMPDIR}
        VIASH_TEMP=${VIASH_TEMP:-$TMP}
        VIASH_TEMP=${VIASH_TEMP:-$TEMPDIR}
        VIASH_TEMP=${VIASH_TEMP:-$TEMP}
        VIASH_TEMP=${VIASH_TEMP:-/tmp}
      fi
      
      # define helper functions
      # ViashQuote: put quotes around non flag values
      # $1     : unquoted string
      # return : possibly quoted string
      # examples:
      #   ViashQuote --foo      # returns --foo
      #   ViashQuote bar        # returns 'bar'
      #   Viashquote --foo=bar  # returns --foo='bar'
      function ViashQuote {
        if [[ "$1" =~ ^-+[a-zA-Z0-9_\-]+=.+$ ]]; then
          echo "$1" | sed "s#=\(.*\)#='\1'#"
        elif [[ "$1" =~ ^-+[a-zA-Z0-9_\-]+$ ]]; then
          echo "$1"
        else
          echo "'$1'"
        fi
      }
      # ViashRemoveFlags: Remove leading flag
      # $1     : string with a possible leading flag
      # return : string without possible leading flag
      # examples:
      #   ViashRemoveFlags --foo=bar  # returns bar
      function ViashRemoveFlags {
        echo "$1" | sed 's/^--*[a-zA-Z0-9_\-]*=//'
      }
      # ViashSourceDir: return the path of a bash file, following symlinks
      # usage   : ViashSourceDir ${BASH_SOURCE[0]}
      # $1      : Should always be set to ${BASH_SOURCE[0]}
      # returns : The absolute path of the bash file
      function ViashSourceDir {
        SOURCE="$1"
        while [ -h "$SOURCE" ]; do
          DIR="$( cd -P "$( dirname "$SOURCE" )" >/dev/null 2>&1 && pwd )"
          SOURCE="$(readlink "$SOURCE")"
          [[ $SOURCE != /* ]] && SOURCE="$DIR/$SOURCE"
        done
        cd -P "$( dirname "$SOURCE" )" >/dev/null 2>&1 && pwd
      }
      # see https://en.wikipedia.org/wiki/Syslog#Severity_level
      VIASH_LOGCODE_EMERGENCY=0
      VIASH_LOGCODE_ALERT=1
      VIASH_LOGCODE_CRITICAL=2
      VIASH_LOGCODE_ERROR=3
      VIASH_LOGCODE_WARNING=4
      VIASH_LOGCODE_NOTICE=5
      VIASH_LOGCODE_INFO=6
      VIASH_LOGCODE_DEBUG=7
      VIASH_VERBOSITY=$VIASH_LOGCODE_NOTICE
      
      # ViashLog: Log events depending on the verbosity level
      # usage: ViashLog 1 alert Oh no something went wrong!
      # $1: required verbosity level
      # $2: display tag
      # $3+: messages to display
      # stdout: Your input, prepended by '[$2] '.
      function ViashLog {
        local required_level="$1"
        local display_tag="$2"
        shift 2
        if [ $VIASH_VERBOSITY -ge $required_level ]; then
          echo "[$display_tag]" "$@"
        fi
      }
      
      # ViashEmergency: log events when the system is unstable
      # usage: ViashEmergency Oh no something went wrong.
      # stdout: Your input, prepended by '[emergency] '.
      function ViashEmergency {
        ViashLog $VIASH_LOGCODE_EMERGENCY emergency "$@"
      }
      
      # ViashAlert: log events when actions must be taken immediately (e.g. corrupted system database)
      # usage: ViashAlert Oh no something went wrong.
      # stdout: Your input, prepended by '[alert] '.
      function ViashAlert {
        ViashLog $VIASH_LOGCODE_ALERT alert "$@"
      }
      
      # ViashCritical: log events when a critical condition occurs
      # usage: ViashCritical Oh no something went wrong.
      # stdout: Your input, prepended by '[critical] '.
      function ViashCritical {
        ViashLog $VIASH_LOGCODE_CRITICAL critical "$@"
      }
      
      # ViashError: log events when an error condition occurs
      # usage: ViashError Oh no something went wrong.
      # stdout: Your input, prepended by '[error] '.
      function ViashError {
        ViashLog $VIASH_LOGCODE_ERROR error "$@"
      }
      
      # ViashWarning: log potentially abnormal events
      # usage: ViashWarning Something may have gone wrong.
      # stdout: Your input, prepended by '[warning] '.
      function ViashWarning {
        ViashLog $VIASH_LOGCODE_WARNING warning "$@"
      }
      
      # ViashNotice: log significant but normal events
      # usage: ViashNotice This just happened.
      # stdout: Your input, prepended by '[notice] '.
      function ViashNotice {
        ViashLog $VIASH_LOGCODE_NOTICE notice "$@"
      }
      
      # ViashInfo: log normal events
      # usage: ViashInfo This just happened.
      # stdout: Your input, prepended by '[info] '.
      function ViashInfo {
        ViashLog $VIASH_LOGCODE_INFO info "$@"
      }
      
      # ViashDebug: log all events, for debugging purposes
      # usage: ViashDebug This just happened.
      # stdout: Your input, prepended by '[debug] '.
      function ViashDebug {
        ViashLog $VIASH_LOGCODE_DEBUG debug "$@"
      }
      
      # find source folder of this component
      VIASH_META_RESOURCES_DIR=`ViashSourceDir ${BASH_SOURCE[0]}`
      
      # backwards compatibility
      VIASH_RESOURCES_DIR="$VIASH_META_RESOURCES_DIR"
      
      # define meta fields
      VIASH_META_FUNCTIONALITY_NAME="concat"
      VIASH_META_EXECUTABLE="$VIASH_META_RESOURCES_DIR/$VIASH_META_FUNCTIONALITY_NAME"
      
      
      # ViashHelp: Display helpful explanation about this executable
      function ViashHelp {
        echo "concat main_build"
        echo ""
        echo "Concatenates several uni-modal samples in .h5mu files into a single file."
        echo ""
        echo "Arguments:"
        echo "    -i, --input"
        echo "        type: file, required parameter, multiple values allowed"
        echo "        example: sample_paths"
        echo "        Paths to the different samples to be concatenated."
        echo ""
        echo "    --sample_names"
        echo "        type: string, required parameter, multiple values allowed"
        echo "        example: sample_names"
        echo "        Names of the different samples that have to be concatenated. Must be of"
        echo "        same length as \`--input\`."
        echo ""
        echo "    -o, --output"
        echo "        type: file, output"
        echo "        example: output.h5mu"
        echo ""
        echo "    --obs_sample_name"
        echo "        type: string"
        echo "        default: sample_id"
        echo "        Name of the .obs key under which to add the sample names."
        echo ""
        echo "    --compression"
        echo "        type: string"
        echo "        default: gzip"
        echo "        The compression format to be used on the final h5mu object."
        echo ""
        echo "    --other_axis_mode"
        echo "        type: string"
        echo "        default: move"
        echo "        choices: [ same, unique, first, only, concat, move ]"
        echo "        How to handle the merging of other axis (var, obs, ...)."
        echo "         - None: keep no data"
        echo "         - same: only keep elements of the matrices which are the same in each"
        echo "        of the samples"
        echo "         - unique: only keep elements for which there is only 1 possible value"
        echo "        (1 value that can occur in multiple samples)"
        echo "         - first: keep the annotation from the first sample"
        echo "         - only: keep elements that show up in only one of the objects (1 unique"
        echo "        element in only 1 sample)"
        echo "         - move: identical to 'same', but moving the conflicting values to .varm"
        echo "        or .obsm"
      }
      
      # initialise array
      VIASH_POSITIONAL_ARGS=''
      VIASH_MODE='run'
      
      while [[ $# -gt 0 ]]; do
          case "$1" in
              -h|--help)
                  ViashHelp
                  exit
                  ;;
              ---v|---verbose)
                  let "VIASH_VERBOSITY=VIASH_VERBOSITY+1"
                  shift 1
                  ;;
              ---verbosity)
                  VIASH_VERBOSITY="$2"
                  shift 2
                  ;;
              ---verbosity=*)
                  VIASH_VERBOSITY="$(ViashRemoveFlags "$1")"
                  shift 1
                  ;;
              --version)
                  echo "concat main_build"
                  exit
                  ;;
              --input)
                  if [ -z "$VIASH_PAR_INPUT" ]; then
                    VIASH_PAR_INPUT="$2"
                  else
                    VIASH_PAR_INPUT="$VIASH_PAR_INPUT,""$2"
                  fi
                  [ $# -lt 2 ] && ViashError Not enough arguments passed to --input. Use "--help" to get more information on the parameters. && exit 1
                  shift 2
                  ;;
              --input=*)
                  if [ -z "$VIASH_PAR_INPUT" ]; then
                    VIASH_PAR_INPUT=$(ViashRemoveFlags "$1")
                  else
                    VIASH_PAR_INPUT="$VIASH_PAR_INPUT,"$(ViashRemoveFlags "$1")
                  fi
                  shift 1
                  ;;
              -i)
                  if [ -z "$VIASH_PAR_INPUT" ]; then
                    VIASH_PAR_INPUT="$2"
                  else
                    VIASH_PAR_INPUT="$VIASH_PAR_INPUT,""$2"
                  fi
                  [ $# -lt 2 ] && ViashError Not enough arguments passed to -i. Use "--help" to get more information on the parameters. && exit 1
                  shift 2
                  ;;
              --sample_names)
                  if [ -z "$VIASH_PAR_SAMPLE_NAMES" ]; then
                    VIASH_PAR_SAMPLE_NAMES="$2"
                  else
                    VIASH_PAR_SAMPLE_NAMES="$VIASH_PAR_SAMPLE_NAMES,""$2"
                  fi
                  [ $# -lt 2 ] && ViashError Not enough arguments passed to --sample_names. Use "--help" to get more information on the parameters. && exit 1
                  shift 2
                  ;;
              --sample_names=*)
                  if [ -z "$VIASH_PAR_SAMPLE_NAMES" ]; then
                    VIASH_PAR_SAMPLE_NAMES=$(ViashRemoveFlags "$1")
                  else
                    VIASH_PAR_SAMPLE_NAMES="$VIASH_PAR_SAMPLE_NAMES,"$(ViashRemoveFlags "$1")
                  fi
                  shift 1
                  ;;
              --output)
                  [ -n "$VIASH_PAR_OUTPUT" ] && ViashError Bad arguments for option \'--output\': \'$VIASH_PAR_OUTPUT\' \& \'$2\' - you should provide exactly one argument for this option. && exit 1
                  VIASH_PAR_OUTPUT="$2"
                  [ $# -lt 2 ] && ViashError Not enough arguments passed to --output. Use "--help" to get more information on the parameters. && exit 1
                  shift 2
                  ;;
              --output=*)
                  [ -n "$VIASH_PAR_OUTPUT" ] && ViashError Bad arguments for option \'--output=*\': \'$VIASH_PAR_OUTPUT\' \& \'$2\' - you should provide exactly one argument for this option. && exit 1
                  VIASH_PAR_OUTPUT=$(ViashRemoveFlags "$1")
                  shift 1
                  ;;
              -o)
                  [ -n "$VIASH_PAR_OUTPUT" ] && ViashError Bad arguments for option \'-o\': \'$VIASH_PAR_OUTPUT\' \& \'$2\' - you should provide exactly one argument for this option. && exit 1
                  VIASH_PAR_OUTPUT="$2"
                  [ $# -lt 2 ] && ViashError Not enough arguments passed to -o. Use "--help" to get more information on the parameters. && exit 1
                  shift 2
                  ;;
              --obs_sample_name)
                  [ -n "$VIASH_PAR_OBS_SAMPLE_NAME" ] && ViashError Bad arguments for option \'--obs_sample_name\': \'$VIASH_PAR_OBS_SAMPLE_NAME\' \& \'$2\' - you should provide exactly one argument for this option. && exit 1
                  VIASH_PAR_OBS_SAMPLE_NAME="$2"
                  [ $# -lt 2 ] && ViashError Not enough arguments passed to --obs_sample_name. Use "--help" to get more information on the parameters. && exit 1
                  shift 2
                  ;;
              --obs_sample_name=*)
                  [ -n "$VIASH_PAR_OBS_SAMPLE_NAME" ] && ViashError Bad arguments for option \'--obs_sample_name=*\': \'$VIASH_PAR_OBS_SAMPLE_NAME\' \& \'$2\' - you should provide exactly one argument for this option. && exit 1
                  VIASH_PAR_OBS_SAMPLE_NAME=$(ViashRemoveFlags "$1")
                  shift 1
                  ;;
              --compression)
                  [ -n "$VIASH_PAR_COMPRESSION" ] && ViashError Bad arguments for option \'--compression\': \'$VIASH_PAR_COMPRESSION\' \& \'$2\' - you should provide exactly one argument for this option. && exit 1
                  VIASH_PAR_COMPRESSION="$2"
                  [ $# -lt 2 ] && ViashError Not enough arguments passed to --compression. Use "--help" to get more information on the parameters. && exit 1
                  shift 2
                  ;;
              --compression=*)
                  [ -n "$VIASH_PAR_COMPRESSION" ] && ViashError Bad arguments for option \'--compression=*\': \'$VIASH_PAR_COMPRESSION\' \& \'$2\' - you should provide exactly one argument for this option. && exit 1
                  VIASH_PAR_COMPRESSION=$(ViashRemoveFlags "$1")
                  shift 1
                  ;;
              --other_axis_mode)
                  [ -n "$VIASH_PAR_OTHER_AXIS_MODE" ] && ViashError Bad arguments for option \'--other_axis_mode\': \'$VIASH_PAR_OTHER_AXIS_MODE\' \& \'$2\' - you should provide exactly one argument for this option. && exit 1
                  VIASH_PAR_OTHER_AXIS_MODE="$2"
                  [ $# -lt 2 ] && ViashError Not enough arguments passed to --other_axis_mode. Use "--help" to get more information on the parameters. && exit 1
                  shift 2
                  ;;
              --other_axis_mode=*)
                  [ -n "$VIASH_PAR_OTHER_AXIS_MODE" ] && ViashError Bad arguments for option \'--other_axis_mode=*\': \'$VIASH_PAR_OTHER_AXIS_MODE\' \& \'$2\' - you should provide exactly one argument for this option. && exit 1
                  VIASH_PAR_OTHER_AXIS_MODE=$(ViashRemoveFlags "$1")
                  shift 1
                  ;;
              ---n_proc)
                  [ -n "$VIASH_META_N_PROC" ] && ViashError Bad arguments for option \'---n_proc\': \'$VIASH_META_N_PROC\' \& \'$2\' - you should provide exactly one argument for this option. && exit 1
                  VIASH_META_N_PROC="$2"
                  [ $# -lt 2 ] && ViashError Not enough arguments passed to ---n_proc. Use "--help" to get more information on the parameters. && exit 1
                  shift 2
                  ;;
              ---n_proc=*)
                  [ -n "$VIASH_META_N_PROC" ] && ViashError Bad arguments for option \'---n_proc=*\': \'$VIASH_META_N_PROC\' \& \'$2\' - you should provide exactly one argument for this option. && exit 1
                  VIASH_META_N_PROC=$(ViashRemoveFlags "$1")
                  shift 1
                  ;;
              ---memory)
                  [ -n "$VIASH_META_MEMORY" ] && ViashError Bad arguments for option \'---memory\': \'$VIASH_META_MEMORY\' \& \'$2\' - you should provide exactly one argument for this option. && exit 1
                  VIASH_META_MEMORY="$2"
                  [ $# -lt 2 ] && ViashError Not enough arguments passed to ---memory. Use "--help" to get more information on the parameters. && exit 1
                  shift 2
                  ;;
              ---memory=*)
                  [ -n "$VIASH_META_MEMORY" ] && ViashError Bad arguments for option \'---memory=*\': \'$VIASH_META_MEMORY\' \& \'$2\' - you should provide exactly one argument for this option. && exit 1
                  VIASH_META_MEMORY=$(ViashRemoveFlags "$1")
                  shift 1
                  ;;
              *)  # positional arg or unknown option
                  # since the positional args will be eval'd, can we always quote, instead of using ViashQuote
                  VIASH_POSITIONAL_ARGS="$VIASH_POSITIONAL_ARGS '$1'"
                  [[ $1 == -* ]] && ViashWarning $1 looks like a parameter but is not a defined parameter and will instead be treated as a positional argument. Use "--help" to get more information on the parameters.
                  shift # past argument
                  ;;
          esac
      done
      
      # parse positional parameters
      eval set -- $VIASH_POSITIONAL_ARGS
      
      
      
      # helper function for parsing memory strings
      function ViashMemoryAsBytes {
        local memory=`echo "$1" | tr '[:upper:]' '[:lower:]' | tr -d '[:space:]'`
        local memory_regex='^([0-9]+)([kmgtp]b?|b)$'
        if [[ $memory =~ $memory_regex ]]; then
          local number=${memory/[^0-9]*/}
          local symbol=${memory/*[0-9]/}
          
          case $symbol in
            b)      memory_b=$number ;;
            kb|k)   memory_b=$(( $number * 1024 )) ;;
            mb|m)   memory_b=$(( $number * 1024 * 1024 )) ;;
            gb|g)   memory_b=$(( $number * 1024 * 1024 * 1024 )) ;;
            tb|t)   memory_b=$(( $number * 1024 * 1024 * 1024 * 1024 )) ;;
            pb|p)   memory_b=$(( $number * 1024 * 1024 * 1024 * 1024 * 1024 )) ;;
          esac
          echo "$memory_b"
        fi
      }
      # compute memory in different units
      if [ ! -z ${VIASH_META_MEMORY+x} ]; then
        VIASH_META_MEMORY_B=`ViashMemoryAsBytes $VIASH_META_MEMORY`
        # do not define other variables if memory_b is an empty string
        if [ ! -z "$VIASH_META_MEMORY_B" ]; then
          VIASH_META_MEMORY_KB=$(( ($VIASH_META_MEMORY_B+1023) / 1024 ))
          VIASH_META_MEMORY_MB=$(( ($VIASH_META_MEMORY_KB+1023) / 1024 ))
          VIASH_META_MEMORY_GB=$(( ($VIASH_META_MEMORY_MB+1023) / 1024 ))
          VIASH_META_MEMORY_TB=$(( ($VIASH_META_MEMORY_GB+1023) / 1024 ))
          VIASH_META_MEMORY_PB=$(( ($VIASH_META_MEMORY_TB+1023) / 1024 ))
        else
          # unset memory if string is empty
          unset $VIASH_META_MEMORY_B
        fi
      fi
      # unset nproc if string is empty
      if [ -z "$VIASH_META_N_PROC" ]; then
        unset $VIASH_META_N_PROC
      fi
      
      
      
      
      # check whether required parameters exist
      if [ -z ${VIASH_PAR_INPUT+x} ]; then
        ViashError '--input' is a required argument. Use "--help" to get more information on the parameters.
        exit 1
      fi
      if [ -z ${VIASH_PAR_SAMPLE_NAMES+x} ]; then
        ViashError '--sample_names' is a required argument. Use "--help" to get more information on the parameters.
        exit 1
      fi
      if [ -z ${VIASH_PAR_OBS_SAMPLE_NAME+x} ]; then
        VIASH_PAR_OBS_SAMPLE_NAME="sample_id"
      fi
      if [ -z ${VIASH_PAR_COMPRESSION+x} ]; then
        VIASH_PAR_COMPRESSION="gzip"
      fi
      if [ -z ${VIASH_PAR_OTHER_AXIS_MODE+x} ]; then
        VIASH_PAR_OTHER_AXIS_MODE="move"
      fi
      
      
      # check whether parameters values are of the right type
      
      
      # check whether parameters values are of the right type
      
      
      
      
      
      if [ ! -z "$VIASH_PAR_OTHER_AXIS_MODE" ]; then
        VIASH_PAR_OTHER_AXIS_MODE_CHOICES=("same:unique:first:only:concat:move")
        IFS=:
        set -f
        if ! [[ ":${VIASH_PAR_OTHER_AXIS_MODE_CHOICES[*]}:" =~ ":$VIASH_PAR_OTHER_AXIS_MODE:" ]]; then
          ViashError '--other_axis_mode' specified value of \'$VIASH_PAR_OTHER_AXIS_MODE\' is not in the list of allowed values. Use "--help" to get more information on the parameters.
          exit 1
        fi
        set +f
        unset IFS
      fi
      
      
      cat << VIASHEOF | bash
      set -e
      tempscript=\$(mktemp "$VIASH_TEMP/viash-run-concat-XXXXXX")
      function clean_up {
        rm "\$tempscript"
      }
      function interrupt {
        echo -e "\nCTRL-C Pressed..."
        exit 1
      }
      trap clean_up EXIT
      trap interrupt INT SIGINT
      cat > "\$tempscript" << 'VIASHMAIN'
      
      from __future__ import annotations
      import logging
      import anndata
      import muon as mu
      from sys import stdout
      import pandas as pd
      import numpy as np
      from collections.abc import Iterable
      from multiprocessing import Pool
      
      ### VIASH START
      # The following code has been auto-generated by Viash.
      par = {
        'input': $( if [ ! -z ${VIASH_PAR_INPUT+x} ]; then echo "'${VIASH_PAR_INPUT//\'/\\\'}'.split(',')"; else echo None; fi ),
        'sample_names': $( if [ ! -z ${VIASH_PAR_SAMPLE_NAMES+x} ]; then echo "'${VIASH_PAR_SAMPLE_NAMES//\'/\\\'}'.split(',')"; else echo None; fi ),
        'output': $( if [ ! -z ${VIASH_PAR_OUTPUT+x} ]; then echo "'${VIASH_PAR_OUTPUT//\'/\\\'}'"; else echo None; fi ),
        'obs_sample_name': $( if [ ! -z ${VIASH_PAR_OBS_SAMPLE_NAME+x} ]; then echo "'${VIASH_PAR_OBS_SAMPLE_NAME//\'/\\\'}'"; else echo None; fi ),
        'compression': $( if [ ! -z ${VIASH_PAR_COMPRESSION+x} ]; then echo "'${VIASH_PAR_COMPRESSION//\'/\\\'}'"; else echo None; fi ),
        'other_axis_mode': $( if [ ! -z ${VIASH_PAR_OTHER_AXIS_MODE+x} ]; then echo "'${VIASH_PAR_OTHER_AXIS_MODE//\'/\\\'}'"; else echo None; fi )
      }
      meta = {
        'functionality_name': $( if [ ! -z ${VIASH_META_FUNCTIONALITY_NAME+x} ]; then echo "'${VIASH_META_FUNCTIONALITY_NAME//\'/\\\'}'"; else echo None; fi ),
        'resources_dir': $( if [ ! -z ${VIASH_META_RESOURCES_DIR+x} ]; then echo "'${VIASH_META_RESOURCES_DIR//\'/\\\'}'"; else echo None; fi ),
        'executable': $( if [ ! -z ${VIASH_META_EXECUTABLE+x} ]; then echo "'${VIASH_META_EXECUTABLE//\'/\\\'}'"; else echo None; fi ),
        'temp_dir': $( if [ ! -z ${VIASH_TEMP+x} ]; then echo "'${VIASH_TEMP//\'/\\\'}'"; else echo None; fi ),
        'n_proc': $( if [ ! -z ${VIASH_META_N_PROC+x} ]; then echo "'${VIASH_META_N_PROC//\'/\\\'}'"; else echo None; fi ),
        'memory_b': $( if [ ! -z ${VIASH_META_MEMORY_B+x} ]; then echo "'${VIASH_META_MEMORY_B//\'/\\\'}'"; else echo None; fi ),
        'memory_kb': $( if [ ! -z ${VIASH_META_MEMORY_KB+x} ]; then echo "'${VIASH_META_MEMORY_KB//\'/\\\'}'"; else echo None; fi ),
        'memory_mb': $( if [ ! -z ${VIASH_META_MEMORY_MB+x} ]; then echo "'${VIASH_META_MEMORY_MB//\'/\\\'}'"; else echo None; fi ),
        'memory_gb': $( if [ ! -z ${VIASH_META_MEMORY_GB+x} ]; then echo "'${VIASH_META_MEMORY_GB//\'/\\\'}'"; else echo None; fi ),
        'memory_tb': $( if [ ! -z ${VIASH_META_MEMORY_TB+x} ]; then echo "'${VIASH_META_MEMORY_TB//\'/\\\'}'"; else echo None; fi ),
        'memory_pb': $( if [ ! -z ${VIASH_META_MEMORY_PB+x} ]; then echo "'${VIASH_META_MEMORY_PB//\'/\\\'}'"; else echo None; fi )
      }
      
      resources_dir = '$VIASH_META_RESOURCES_DIR'
      
      ### VIASH END
      
      logger = logging.getLogger()
      logger.setLevel(logging.INFO)
      console_handler = logging.StreamHandler(stdout)
      logFormatter = logging.Formatter("%(asctime)s %(levelname)-8s %(message)s")
      console_handler.setFormatter(logFormatter)
      logger.addHandler(console_handler)
      
      def add_sample_names(sample_ids: tuple[str], samples: Iterable[mu.MuData], obs_key_sample_name: str) -> None:
          """
          Add sample names to the observations for each sample.
          """
          for (sample_id, sample) in zip(sample_ids, samples):
              if obs_key_sample_name in sample.obs_keys():
                  logger.info(f'Column .obs["{obs_key_sample_name}"] already exists in sample "{sample_id}". Overriding the value for this column.')
                  samples.obs = sample.obs.drop(obs_key_sample_name, axis=1)
              for modality in sample.mod.values():
                  modality.obs[obs_key_sample_name] = sample_id
              sample.update()
      
      
      def make_observation_keys_unique(sample_ids: tuple[str], samples: Iterable[mu.MuData]) -> None:
          """
          Make the observation keys unique across all samples. At input,
          the observation keys are unique within a sample. By adding the sample name
          (unique for a sample) to each observation key, the observation key is made
          unique across all samples as well.
          """
          logger.info('Making observation keys unique across all samples.')
          for sample_id, sample in zip(sample_ids, samples):
              sample.obs.index = f"{sample_id}_" + sample.obs.index
              make_observation_keys_unique_per_mod(sample_id, sample)
      
      
      def make_observation_keys_unique_per_mod(sample_id: str, sample: mu.MuData) -> None:
          """
          Updating MuData.obs_names is not allowed (it is read-only).
          So the observation keys for each modality has to be updated manually.
          """
          for mod in sample.mod.values():
              mod.obs_names = f"{sample_id}_" + mod.obs_names
      
      
      def group_modalities(samples: Iterable[anndata.AnnData]) -> dict[str, anndata.AnnData]:
          """
          Split up the modalities of all samples and group them per modality.
          """
          mods = {}
          for sample in samples:
              for mod_name, mod in sample.mod.items():
                  mods.setdefault(mod_name, []).append(mod)
      
          if len(set(len(mod) for mod in mods.values())) != 1:
              logger.warning("One or more samples seem to have a different number of modalities.")
      
          logger.info("Successfully sorted modalities for the different samples.")
          return mods
      
      def nunique(row):
          unique = pd.unique(row)
          unique_without_na = pd.core.dtypes.missing.remove_na_arraylike(unique)
          return len(unique_without_na)
      
      def any_row_contains_duplicate_values(n_processes: int, frame: pd.DataFrame) -> bool:
          """
          Check if any row contains duplicate values, that are not NA.
          """
          numpy_array = frame.to_numpy()
          with Pool(n_processes) as pool:
              number_of_unique = pool.map(nunique, iter(numpy_array))
          number_of_unique = pd.Series(number_of_unique, index=frame.index)
          non_na_counts = frame.count(axis=1)
          is_duplicated = (number_of_unique - non_na_counts) != 0
          return is_duplicated.any()
      
      def concatenate_matrices(n_processes: int, sample_ids: tuple[str], matrices: Iterable[pd.DataFrame]) \\
          -> tuple[dict[str, pd.DataFrame], pd.DataFrame | None, dict[str, pd.core.dtypes.dtypes.Dtype]]:
          """
          Merge matrices by combining columns that have the same name.
          Columns that contain conflicting values (e.i. the columns have different values),
          are not merged, but instead moved to a new dataframe.
          """
          column_names = set(column_name for var in matrices for column_name in var)
          logger.debug('Trying to concatenate columns: %s.', ",".join(column_names))
          if not column_names:
              return {}, None
          conflicts, concatenated_matrix = \\
              split_conflicts_and_concatenated_columns(n_processes,
                                                       sample_ids,
                                                       matrices,
                                                       column_names)
          original_dtypes = get_original_dtypes(matrices, column_names)
          concatenated_matrix = set_dtypes_concatenated_columns(original_dtypes, concatenated_matrix)
          conflicts = set_dtypes_conflicts(original_dtypes, conflicts)
          return conflicts, concatenated_matrix
      
      def set_dtypes_conflicts(original_dtypes: dict[str, pd.core.dtypes.dtypes.Dtype],
                               conflicts: tuple[dict[str, pd.DataFrame], pd.DataFrame]) -> \\
                              tuple[dict[str, pd.DataFrame], pd.DataFrame]:
          """
          Ensure the correct datatypes for the conflict dataframes.
          """
          conflicts_correct_dtypes = {}
          for conflict_name, confict_data in conflicts.items():
              original_dtype = original_dtypes[conflict_name.removeprefix('conflict_')]
              new_conflict_dtypes = {column: original_dtype for column in confict_data.columns}
              confict_data = cast_to_original_dtype(confict_data, new_conflict_dtypes)
              conflicts_correct_dtypes[conflict_name] = confict_data
          return conflicts_correct_dtypes
      
      def set_dtypes_concatenated_columns(original_dtypes: dict[str, pd.core.dtypes.dtypes.Dtype],
                                          concatenated_matrix: pd.DataFrame) -> pd.DataFrame:
          """
          Ensure the correct datatypes for the concatenated columns that did not contain conflicts.
          """
          curr_concat_matrix_cols_dtypes = {col: dtype for col, dtype in original_dtypes.items() 
                                            if col in concatenated_matrix.columns}
          return cast_to_original_dtype(concatenated_matrix, curr_concat_matrix_cols_dtypes)
      
      def get_first_non_na_value_vector(df):
          numpy_arr = df.to_numpy()
          n_rows, n_cols = numpy_arr.shape
          col_index = pd.isna(numpy_arr).argmin(axis=1)
          flat_index = n_cols * np.arange(n_rows) + col_index
          return pd.Series(numpy_arr.ravel()[flat_index], index=df.index, name=df.columns[0])
      
      def split_conflicts_and_concatenated_columns(n_processes: int,
                                                   sample_ids: tuple[str],
                                                   matrices: Iterable[pd.DataFrame],
                                                   column_names: Iterable[str]) -> \\
                                                  tuple[dict[str, pd.DataFrame], pd.DataFrame]:
          """
          Retrieve columns with the same name from a list of dataframes which are 
          identical across all the frames (ignoring NA values).
          Columns which are not the same are regarded as 'conflicts',
          which are stored in seperate dataframes, one per columns
          with the same name that store conflicting values.
          """
          conflicts = {}
          concatenated_matrix = []
          for column_name in column_names:
              columns = [var[column_name] for var in matrices if column_name in var]
              assert columns, "Some columns should have been found."
              concatenated_columns = pd.concat(columns, axis=1, join="outer")
              if any_row_contains_duplicate_values(n_processes, concatenated_columns):
                  concatenated_columns.columns = sample_ids
                  conflicts[f'conflict_{column_name}'] = concatenated_columns
              else:
                  unique_values = get_first_non_na_value_vector(concatenated_columns)
                  # concatenated_columns.fillna(method='bfill', axis=1).iloc[:, 0]
                  concatenated_matrix.append(unique_values)
          if concatenated_matrix:
              concatenated_matrix = pd.concat(concatenated_matrix, join="outer", axis=1)
          else:
              concatenated_matrix = pd.DataFrame()
              
          return conflicts, concatenated_matrix
      
      def cast_to_original_dtype(result: pd.DataFrame,
                                 orignal_dtypes: dict[str, pd.core.dtypes.dtypes.Dtype]) -> pd.DataFrame:
          """
          Cast the dataframe to dtypes that can be written by mudata.
          """
          logger.debug('Trying to cast to "category" or keep original datatype.')
          for col_name, orig_dtype in orignal_dtypes.items():
              try:
                  result = result.astype({col_name: "category"}, copy=True)
                  result[col_name].cat.categories = result[col_name].cat.categories.astype(str)
              except (ValueError, TypeError):
                  try:
                      result = result.astype({col_name: orig_dtype}, copy=True)
                  except (ValueError, TypeError):
                      logger.warning("Could not keep datatype for column %s", col_name)
          return result
      
      
      def get_original_dtypes(matrices: Iterable[pd.DataFrame], 
                              column_names: Iterable[str]) -> \\
                              dict[str, pd.core.dtypes.dtypes.Dtype]:
          """
          Get the datatypes of columns in a list of dataframes.
          If a column occurs in more than 1 dataframe, includes the dtype of the column
          in the dataframe that comes first in the list.
          """
          dtypes = {}
          for col_name in column_names:
              for matrix in matrices:
                  col = matrix.get(col_name, None)
                  if col is not None and col_name not in dtypes:
                      dtypes[col_name] = col.dtype
          return dtypes
      
      
      def split_conflicts_modalities(n_processes: int, sample_ids: tuple[str], modalities: Iterable[anndata.AnnData]) \\
              -> tuple[dict[str, dict[str, pd.DataFrame]],  dict[str, pd.DataFrame | None]]:
              """
              Merge .var and .obs matrices of the anndata objects. Columns are merged
              when the values (excl NA) are the same in each of the matrices.
              Conflicting columns are moved to a separate dataframe (one dataframe for each column, 
              containing all the corresponding column from each sample). 
              """
              matrices_to_parse = ("var", "obs")
              concatenated_result = {}
              conflicts_result = {}
              for matrix_name in matrices_to_parse:
                  matrices = [getattr(modality, matrix_name) for modality in modalities]
                  conflicts, concatenated_matrix = concatenate_matrices(n_processes, sample_ids, matrices)
                  conflicts_result[f"{matrix_name}m"] = conflicts
                  concatenated_result[matrix_name] = concatenated_matrix
              return conflicts_result, concatenated_result
      
      def set_matrices(concatenated_data: mu.MuData, 
                       mod_name: str,
                       new_matrices: dict[str, pd.DataFrame | None]) -> mu.MuData:
          """
          Add the calculated matrices to the mudata object. Ensure the correct datatypes
          for the matrices that are composed from the combination of the matrices
          from the different modalities.
          """
          mod = concatenated_data.mod[mod_name]
          original_dtypes_global_matrices = {
              global_matrix_name: getattr(concatenated_data, global_matrix_name).dtypes
              for global_matrix_name 
              in new_matrices.keys()
          }
          for matrix_name, data in new_matrices.items():
              new_index = getattr(mod, matrix_name).index
              if data is None:
                  data = pd.DataFrame(index=new_index)
              if data.index.empty:
                  data.index = new_index
              setattr(mod, matrix_name, data)
          # After setting the matrices (.e.g. .mod['rna'].var) for each of the modalities
          # the 'global' matrices must also be updated. This is done by mudata automatically
          # by calling mudata.update() before writing. However, we need to make sure that the
          # dtypes of these global matrices are also correct for writing..
          for global_matrix_name, dtypes in original_dtypes_global_matrices.items():
              matrix = getattr(concatenated_data, global_matrix_name)
              setattr(concatenated_data, global_matrix_name, cast_to_original_dtype(matrix, dtypes))
          return concatenated_data
      
      def set_conflicts(concatenated_data: mu.MuData,
                        mod_name: str,
                        conflicts: dict[str, dict[str, pd.DataFrame]]) -> mu.MuData:
          """
          Store dataframes containing the conflicting columns in .obsm,
          one key per column name from the original data.
          """
          mod = concatenated_data.mod[mod_name]
          mutlidim_to_singledim = {
              'varm': 'var',
              'obsm': 'obs'
          }
          for conflict_matrix_name, conflict in conflicts.items():
              for conflict_name, conflict_data in conflict.items():
                  singledim_name = mutlidim_to_singledim[conflict_matrix_name]
                  singledim_index = getattr(mod, singledim_name).index
                  getattr(mod, conflict_matrix_name)[conflict_name] = conflict_data.reindex(singledim_index)
          concatenated_data.update()
          return concatenated_data
      
      def concatenate_modalities(n_processes: int, sample_ids: tuple[str], modalities: dict[str, Iterable[anndata.AnnData]],
                                 other_axis_mode: str) -> mu.MuData:
          """
          Join the modalities together into a single multimodal sample.
          """
          logger.info('Concatenating samples.')
          concat_modes = {
              "move": None,
          }
          other_axis_mode_to_apply = concat_modes.get(other_axis_mode, other_axis_mode)
          new_mods = {mod_name: anndata.concat(modes,
                                               join='outer',
                                               merge=other_axis_mode_to_apply)
                      for mod_name, modes in modalities.items()}
          concatenated_data = mu.MuData(new_mods)
          logger.info('Concatenated data shape: %s', concatenated_data.shape)
          if other_axis_mode == "move":
              for mod_name, modes in modalities.items():
                  conflicts, new_matrices = split_conflicts_modalities(n_processes, sample_ids, modes)
                  concatenated_data = set_conflicts(concatenated_data, mod_name, conflicts)
                  concatenated_data = set_matrices(concatenated_data, mod_name, new_matrices)
          logger.info("Concatenation successful.")
          return concatenated_data
      
      
      def main() -> None:
          # Read in sample names and sample .h5mu files
          sample_ids: tuple[str] = tuple(i.strip() for i in par["sample_names"])
          samples: list[mu.MuData] = [mu.read(path.strip()) for path in par["input"]]
      
          if len(sample_ids) != len(samples):
              raise ValueError("The number of sample names must match the number of sample files.")
      
          if len(set(par["sample_names"])) != len(par["sample_names"]):
              raise ValueError("The sample names should be unique.")
      
          logger.info("\\nConcatenating data for:\\n\\t%s\\nFrom paths:\\n\\t%s",
                      "\\n\\t".join(sample_ids),
                      "\\n\\t".join(par["input"]))
      
          add_sample_names(sample_ids, samples, par["obs_sample_name"])
          make_observation_keys_unique(sample_ids, samples)
      
          mods = group_modalities(samples)
          n_processes = int(meta["n_proc"]) if meta["n_proc"] else 1
          concatenated_samples = concatenate_modalities(n_processes,
                                                        sample_ids,
                                                        mods,
                                                        par["other_axis_mode"])
          logger.info("Writing out data to '%s' with compression '%s'.",
                      par["output"], par["compression"])
          concatenated_samples.write(par["output"], compression=par["compression"])
      
      
      if __name__ == "__main__":
          main()
      
      VIASHMAIN
      python "\$tempscript" &
      wait "\$!"
      
      VIASHEOF
      

    dest: "concat"
    is_executable: true
  description: "Concatenates several uni-modal samples in .h5mu files into a single\
    \ file.\n"
  test_resources:
  - type: "python_script"
    path: "test.py"
    is_executable: true
  - type: "file"
    path: "../../../resources_test/concat_test_data/e18_mouse_brain_fresh_5k_filtered_feature_bc_matrix_subset.h5mu"
  - type: "file"
    path: "../../../resources_test/concat_test_data/human_brain_3k_filtered_feature_bc_matrix_subset.h5mu"
  info: {}
  status: "enabled"
  requirements:
    commands: []
  dummy_arguments: []
  set_wd_to_resources_dir: false
platform:
  type: "native"
  id: "native"
platforms: []
info:
  config: "src/integrate/concat/config.vsh.yaml"
  platform: "native"
  output: "target/native/integrate/concat"
  executable: "target/native/integrate/concat/concat"
  viash_version: "0.6.0"
  git_commit: "170aecae3e8420f9b51784265c9a7a488bf009ba"
  git_remote: "https://github.com/openpipelines-bio/openpipeline"
