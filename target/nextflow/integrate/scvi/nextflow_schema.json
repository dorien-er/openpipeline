{
    "$schema": "http://json-schema.org/draft-07/schema",
    "title": "scvi",
    "description": "Performs scvi integration as done in the human lung cell atlas https://github.com/LungCellAtlas/HLCA",
    "type": "object",
    "definitions": {
      "inputs" : {
        "title": "Inputs",
        "type": "object",
        "description": "No description",
        "properties": {
          "input": {
            "type": "string",
            "description": "Input h5mu file",
            "default": ""
          },
          "modality": {
            "type": "string",
            "description": "No description",
            "default": "rna"
          },
          "input_layer": {
            "type": "string",
            "description": "Input layer to use. If None, X is used",
            "default": ""
          },
          "obs_batch": {
            "type": "string",
            "description": "Column name discriminating between your batches.",
            "default": "sample_id"
          },
          "var_input": {
            "type": "string",
            "description": ".var column containing highly variable genes. By default, do not subset genes.",
            "default": ""
          },
          "obs_labels": {
            "type": "string",
            "description": "Key in adata.obs for label information. Categories will automatically be ","help_text": "Key in adata.obs for label information. Categories will automatically be \nconverted into integer categories and saved to adata.obs[\u0027_scvi_labels\u0027].\nIf None, assigns the same label to all the data.\n",
            "default": ""
          },
          "obs_size_factor": {
            "type": "string",
            "description": "Key in adata.obs for size factor information. Instead of using library size as a size factor,","help_text": "Key in adata.obs for size factor information. Instead of using library size as a size factor,\nthe provided size factor column will be used as offset in the mean of the likelihood.\nAssumed to be on linear scale.\n",
            "default": ""
          },
          "obs_categorical_covariate": {
            "type": "string",
            "description": "Keys in adata.obs that correspond to categorical data. These covariates can be added in","help_text": "Keys in adata.obs that correspond to categorical data. These covariates can be added in\naddition to the batch covariate and are also treated as nuisance factors\n(i.e., the model tries to minimize their effects on the latent space).\nThus, these should not be used for biologically-relevant factors that you do _not_ want to correct for.\n",
            "default": ""
          },
          "obs_continuous_covariate": {
            "type": "string",
            "description": "Keys in adata.obs that correspond to continuous data. These covariates can be added in","help_text": "Keys in adata.obs that correspond to continuous data. These covariates can be added in\naddition to the batch covariate and are also treated as nuisance factors\n(i.e., the model tries to minimize their effects on the latent space). Thus, these should not be\nused for biologically-relevant factors that you do _not_ want to correct for.\n",
            "default": ""
          }
          
        }
      },
      "outputs" : {
        "title": "Outputs",
        "type": "object",
        "description": "No description",
        "properties": {
          "output": {
            "type": "string",
            "description": "Output h5mu file.",
            "default": "$id.$key.output.output"
          },
          "model_output": {
            "type": "string",
            "description": "Folder where the state of the trained model will be saved to.",
            "default": "$id.$key.model_output.model_output"
          },
          "output_compression": {
            "type": "string",
            "description": "The compression format to be used on the output h5mu object.","enum": ["gzip", "lzf"],
            "default": ""
          },
          "obsm_output": {
            "type": "string",
            "description": "In which .obsm slot to store the resulting integrated embedding.",
            "default": "X_scvi_integrated"
          }
          
        }
      },
      "scvi options" : {
        "title": "SCVI options",
        "type": "object",
        "description": "No description",
        "properties": {
          "n_hidden_nodes": {
            "type": "integer",
            "description": "Number of nodes per hidden layer.",
            "default": "128"
          },
          "n_dimensions_latent_space": {
            "type": "integer",
            "description": "Dimensionality of the latent space.",
            "default": "30"
          },
          "n_hidden_layers": {
            "type": "integer",
            "description": "Number of hidden layers used for encoder and decoder neural-networks.",
            "default": "2"
          },
          "dropout_rate": {
            "type": "number",
            "description": "Dropout rate for the neural networks.",
            "default": "0.1"
          },
          "dispersion": {
            "type": "string",
            "description": "Set the behavior for the dispersion for negative binomial distributions:","help_text": "Set the behavior for the dispersion for negative binomial distributions:\n- gene: dispersion parameter of negative binomial is constant per gene across cells\n- gene-batch: dispersion can differ between different batches\n- gene-label: dispersion can differ between different labels\n- gene-cell:  dispersion can differ for every gene in every cell\n","enum": ["gene", "gene-batch", "gene-label", "gene-cell"],
            "default": "gene"
          },
          "gene_likelihood": {
            "type": "string",
            "description": "Model used to generate the expression data from a count-based likelihood distribution.","help_text": "Model used to generate the expression data from a count-based likelihood distribution.\n- nb: Negative binomial distribution\n- zinb: Zero-inflated negative binomial distribution\n- poisson: Poisson distribution\n","enum": ["nb", "zinb", "poisson"],
            "default": "nb"
          }
          
        }
      },
      "variational auto-encoder model options" : {
        "title": "Variational auto-encoder model options",
        "type": "object",
        "description": "No description",
        "properties": {
          "use_layer_normalization": {
            "type": "string",
            "description": "Neural networks for which to enable layer normalization. ","help_text": "Neural networks for which to enable layer normalization. \n","enum": ["encoder", "decoder", "none", "both"],
            "default": "both"
          },
          "use_batch_normalization": {
            "type": "string",
            "description": "Neural networks for which to enable batch normalization. ","help_text": "Neural networks for which to enable batch normalization. \n","enum": ["encoder", "decoder", "none", "both"],
            "default": "none"
          },
          "encode_covariates": {
            "type": "boolean",
            "description": "Whether to concatenate covariates to expression in encoder",
            "default": "True"
          },
          "deeply_inject_covariates": {
            "type": "boolean",
            "description": "Whether to concatenate covariates into output of hidden layers in encoder/decoder. ","help_text": "Whether to concatenate covariates into output of hidden layers in encoder/decoder. \nThis option only applies when n_layers \u003e 1. The covariates are concatenated to\nthe input of subsequent hidden layers.\n",
            "default": "False"
          },
          "use_observed_lib_size": {
            "type": "boolean",
            "description": "Use observed library size for RNA as scaling factor in mean of conditional distribution.","help_text": "Use observed library size for RNA as scaling factor in mean of conditional distribution.\n",
            "default": "False"
          }
          
        }
      },
      "early stopping arguments" : {
        "title": "Early stopping arguments",
        "type": "object",
        "description": "No description",
        "properties": {
          "early_stopping": {
            "type": "boolean",
            "description": "Whether to perform early stopping with respect to the validation set.",
            "default": ""
          },
          "early_stopping_monitor": {
            "type": "string",
            "description": "Metric logged during validation set epoch.","enum": ["elbo_validation", "reconstruction_loss_validation", "kl_local_validation"],
            "default": "elbo_validation"
          },
          "early_stopping_patience": {
            "type": "integer",
            "description": "Number of validation epochs with no improvement after which training will be stopped.",
            "default": "45"
          },
          "early_stopping_min_delta": {
            "type": "number",
            "description": "Minimum change in the monitored quantity to qualify as an improvement, i.e. an absolute change of less than min_delta, will count as no improvement.",
            "default": "0.0"
          }
          
        }
      },
      "learning parameters" : {
        "title": "Learning parameters",
        "type": "object",
        "description": "No description",
        "properties": {
          "max_epochs": {
            "type": "integer",
            "description": "Number of passes through the dataset, defaults to (20000 / number of cells) * 400 or 400; whichever is smallest.",
            "default": ""
          },
          "reduce_lr_on_plateau": {
            "type": "boolean",
            "description": "Whether to monitor validation loss and reduce learning rate when validation set `lr_scheduler_metric` plateaus.",
            "default": "True"
          },
          "lr_factor": {
            "type": "number",
            "description": "Factor to reduce learning rate.",
            "default": "0.6"
          },
          "lr_patience": {
            "type": "number",
            "description": "Number of epochs with no improvement after which learning rate will be reduced.",
            "default": "30"
          }
          
        }
      },
      "data validition" : {
        "title": "Data validition",
        "type": "object",
        "description": "No description",
        "properties": {
          "n_obs_min_count": {
            "type": "integer",
            "description": "Minimum number of cells threshold ensuring that every obs_batch category has sufficient observations (cells) for model training.",
            "default": "0"
          },
          "n_var_min_count": {
            "type": "integer",
            "description": "Minimum number of genes threshold ensuring that every var_input filter has sufficient observations (genes) for model training.",
            "default": "0"
          }
          
        }
      },
      "nextflow input-output arguments" : {
        "title": "Nextflow input-output arguments",
        "type": "object",
        "description": "Input/output parameters for Nextflow itself. Please note that both publishDir and publish_dir are supported but at least one has to be configured.",
        "properties": {
          "publish_dir": {
            "type": "string",
            "description": "Path to an output directory.",
            "default": ""
          },
          "param_list": {
            "type": "string",
            "description": "Allows inputting multiple parameter sets to initialise a Nextflow channel. A `param_list` can either be a list of maps, a csv file, a json file, a yaml file, or simply a yaml blob.","help_text": "Allows inputting multiple parameter sets to initialise a Nextflow channel. A `param_list` can either be a list of maps, a csv file, a json file, a yaml file, or simply a yaml blob.\n\n* A list of maps (as-is) where the keys of each map corresponds to the arguments of the pipeline. Example: in a `nextflow.config` file: `param_list: [ [\u0027id\u0027: \u0027foo\u0027, \u0027input\u0027: \u0027foo.txt\u0027], [\u0027id\u0027: \u0027bar\u0027, \u0027input\u0027: \u0027bar.txt\u0027] ]`.\n* A csv file should have column names which correspond to the different arguments of this pipeline. Example: `--param_list data.csv` with columns `id,input`.\n* A json or a yaml file should be a list of maps, each of which has keys corresponding to the arguments of the pipeline. Example: `--param_list data.json` with contents `[ {\u0027id\u0027: \u0027foo\u0027, \u0027input\u0027: \u0027foo.txt\u0027}, {\u0027id\u0027: \u0027bar\u0027, \u0027input\u0027: \u0027bar.txt\u0027} ]`.\n* A yaml blob can also be passed directly as a string. Example: `--param_list \"[ {\u0027id\u0027: \u0027foo\u0027, \u0027input\u0027: \u0027foo.txt\u0027}, {\u0027id\u0027: \u0027bar\u0027, \u0027input\u0027: \u0027bar.txt\u0027} ]\"`.\n\nWhen passing a csv, json or yaml file, relative path names are relativized to the location of the parameter file. No relativation is performed when `param_list` is a list of maps (as-is) or a yaml blob.","hidden": true,
            "default": ""
          }
          
        }
      }
    },
    "allOf": [
      {
        "$ref": "#/definitions/inputs"
      },
      {
        "$ref": "#/definitions/outputs"
      },
      {
        "$ref": "#/definitions/scvi options"
      },
      {
        "$ref": "#/definitions/variational auto-encoder model options"
      },
      {
        "$ref": "#/definitions/early stopping arguments"
      },
      {
        "$ref": "#/definitions/learning parameters"
      },
      {
        "$ref": "#/definitions/data validition"
      },
      {
        "$ref": "#/definitions/nextflow input-output arguments"
      }
      ]
}
