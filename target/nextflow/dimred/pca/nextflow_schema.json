{
    "$schema": "http://json-schema.org/draft-07/schema",
    "title": "pca",
    "description": "Computes PCA coordinates, loadings and variance decomposition. Uses the implementation of scikit-learn [Pedregosa11].\n",
    "type": "object",
    "definitions": {
      "arguments" : {
        "title": "Arguments",
        "type": "object",
        "description": "No description",
        "default": "",
        "properties": {
          "input": {
            "type":"string",
            "description": "Input h5mu file",
            
            
            "default": ""
          },
          "modality": {
            "type":"string",
            "description": "No description",
            
            
            "default": "rna"
          },
          "layer": {
            "type":"string",
            "description": "use specified layer for expression values instead of the .X object from the modality.",
            
            
            "default": ""
          },
          "output": {
            "type":"string",
            "description": "Output h5mu file.",
            
            
            "default": "$id.$key.output.h5mu"
          },
          "obsm_output": {
            "type":"string",
            "description": "In which .obsm slot to store the resulting embedding.",
            
            
            "default": "X_pca"
          },
          "varm_output": {
            "type":"string",
            "description": "In which .varm slot to store the resulting loadings matrix.",
            
            
            "default": "pca_loadings"
          },
          "uns_output": {
            "type":"string",
            "description": "In which .uns slot to store the resulting variance objects.",
            
            
            "default": "pca_variance"
          },
          "num_components": {
            "type":"integer",
            "description": "Number of principal components to compute. Defaults to 50, or 1 - minimum dimension size of selected representation.",
            
            
            "default": ""
          }
        }
      },
      "nextflow input-output arguments" : {
        "title": "Nextflow input-output arguments",
        "type": "object",
        "description": "Input/output parameters for Nextflow itself. Please note that both publishDir and publish_dir are supported but at least one has to be configured.",
        "default": "",
        "properties": {
          "publish_dir": {
            "type":"string",
            "description": "Path to an output directory.",
            
            
            "default": ""
          },
          "param_list": {
            "type":"string",
            "description": "Allows inputting multiple parameter sets to initialise a Nextflow channel. Possible formats are csv, json, yaml, or simply a yaml_blob.\nA csv should have column names which correspond to the different arguments of this pipeline.\nA json or a yaml file should be a list of maps, each of which has keys corresponding to the arguments of the pipeline.\nA yaml blob can also be passed directly as a parameter.\nInside the Nextflow pipeline code, params.params_list can also be used to directly a list of parameter sets.\nWhen passing a csv, json or yaml, relative path names are relativized to the location of the parameter file.",
            "hidden": true,
            
            "default": ""
          },
          "param_list_format": {
            "type":"string",
            "description": "Manually specify the param_list_format. Must be one of \u0027csv\u0027, \u0027json\u0027, \u0027yaml\u0027, \u0027yaml_blob\u0027, \u0027asis\u0027 or \u0027none\u0027.",
            "hidden": true,
            "enum": ["csv", "json", "yaml", "yaml_blob", "asis", "none"],
            "default": ""
          }
        }
      }
    },
    "allOf": [
      {
        "$ref": "#/definitions/arguments"
      },
      {
        "$ref": "#/definitions/nextflow input-output arguments"
      }
      
    ]
}
