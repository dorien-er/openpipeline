{
    "$schema": "http://json-schema.org/draft-07/schema",
    "title": "cellbender_remove_background",
    "description": "Eliminating technical artifacts from high-throughput single-cell RNA sequencing data.\n\nThis module removes counts due to ambient RNA molecules and random barcode swapping from (raw) UMI-based scRNA-seq count matrices. \nAt the moment, only the count matrices produced by the CellRanger count pipeline is supported. Support for additional tools and protocols \nwill be added in the future. A quick start tutorial can be found here.\n\nFleming et al. 2022, bioRxiv.\n",
    "type": "object",
    "definitions": {
      "inputs" : {
        "title": "Inputs",
        "type": "object",
        "description": "No description",
        "properties": {
          "input": {
            "type": "string",
            "description": "Input h5mu file. Data file on which to run tool. Data must be un-filtered: it should include empty droplets.",
            "default": ""
          },
          "modality": {
            "type": "string",
            "description": "List of modalities to process.",
            "default": "rna"
          }
          
        }
      },
      "outputs" : {
        "title": "Outputs",
        "type": "object",
        "description": "No description",
        "properties": {
          "output": {
            "type": "string",
            "description": "Full count matrix as an h5mu file, with background RNA removed. This file contains all the original droplet barcodes.",
            "default": "$id.$key.output.h5mu"
          },
          "output_compression": {
            "type": "string",
            "description": "No description","enum": ["gzip", "lzf"],
            "default": ""
          },
          "layer_output": {
            "type": "string",
            "description": "Output layer",
            "default": "cellbender_corrected"
          },
          "obs_background_fraction": {
            "type": "string",
            "description": "No description",
            "default": "cellbender_background_fraction"
          },
          "obs_cell_probability": {
            "type": "string",
            "description": "No description",
            "default": "cellbender_cell_probability"
          },
          "obs_cell_size": {
            "type": "string",
            "description": "No description",
            "default": "cellbender_cell_size"
          },
          "obs_droplet_efficiency": {
            "type": "string",
            "description": "No description",
            "default": "cellbender_droplet_efficiency"
          },
          "obs_latent_scale": {
            "type": "string",
            "description": "No description",
            "default": "cellbender_latent_scale"
          },
          "var_ambient_expression": {
            "type": "string",
            "description": "No description",
            "default": "cellbender_ambient_expression"
          },
          "obsm_gene_expression_encoding": {
            "type": "string",
            "description": "No description",
            "default": "cellbender_gene_expression_encoding"
          }
          
        }
      },
      "arguments" : {
        "title": "Arguments",
        "type": "object",
        "description": "No description",
        "properties": {
          "expected_cells_from_qc": {
            "type": "boolean",
            "description": "Will use the Cell Ranger QC to determine the estimated number of cells",
            "default": "False"
          },
          "expected_cells": {
            "type": "integer",
            "description": "Number of cells expected in the dataset (a rough estimate within a factor of 2 is sufficient).",
            "default": ""
          },
          "total_droplets_included": {
            "type": "integer",
            "description": "The number of droplets from the rank-ordered UMI plot","help_text": "The number of droplets from the rank-ordered UMI plot\nthat will have their cell probabilities inferred as an\noutput. Include the droplets which might contain cells.\nDroplets beyond TOTAL_DROPLETS_INCLUDED should be\n\u0027surely empty\u0027 droplets.\n",
            "default": ""
          },
          "force_cell_umi_prior": {
            "type": "integer",
            "description": "Ignore CellBender\u0027s heuristic prior estimation, and use this prior for UMI counts in cells.",
            "default": ""
          },
          "force_empty_umi_prior": {
            "type": "integer",
            "description": "Ignore CellBender\u0027s heuristic prior estimation, and use this prior for UMI counts in empty droplets.",
            "default": ""
          },
          "model": {
            "type": "string",
            "description": "Which model is being used for count data.","help_text": "Which model is being used for count data.\n\n* \u0027naive\u0027 subtracts the estimated ambient profile.\n* \u0027simple\u0027 does not model either ambient RNA or random barcode swapping (for debugging purposes -- not recommended).\n* \u0027ambient\u0027 assumes background RNA is incorporated into droplets.\n* \u0027swapping\u0027 assumes background RNA comes from random barcode swapping (via PCR chimeras).\n* \u0027full\u0027 uses a combined ambient and swapping model.\n","enum": ["naive", "simple", "ambient", "swapping", "full"],
            "default": "full"
          },
          "epochs": {
            "type": "integer",
            "description": "Number of epochs to train.",
            "default": "150"
          },
          "low_count_threshold": {
            "type": "integer",
            "description": "Droplets with UMI counts below this number are completely ","help_text": "Droplets with UMI counts below this number are completely \nexcluded from the analysis. This can help identify the correct \nprior for empty droplet counts in the rare case where empty \ncounts are extremely high (over 200).\n",
            "default": "5"
          },
          "z_dim": {
            "type": "integer",
            "description": "Dimension of latent variable z.","help_text": "Dimension of latent variable z.\n",
            "default": "64"
          },
          "z_layers": {
            "type": "integer",
            "description": "Dimension of hidden layers in the encoder for z.","help_text": "Dimension of hidden layers in the encoder for z.\n",
            "default": "[512]"
          },
          "training_fraction": {
            "type": "number",
            "description": "Training detail: the fraction of the data used for training.","help_text": "Training detail: the fraction of the data used for training.\nThe rest is never seen by the inference algorithm. Speeds up learning.\n",
            "default": "0.9"
          },
          "empty_drop_training_fraction": {
            "type": "number",
            "description": "Training detail: the fraction of the training data each epoch that ","help_text": "Training detail: the fraction of the training data each epoch that \nis drawn (randomly sampled) from surely empty droplets.\n",
            "default": "0.2"
          },
          "ignore_features": {
            "type": "integer",
            "description": "Integer indices of features to ignore entirely. In the output","help_text": "Integer indices of features to ignore entirely. In the output\ncount matrix, the counts for these features will be unchanged.\n",
            "default": ""
          },
          "fpr": {
            "type": "number",
            "description": "Target \u0027delta\u0027 false positive rate in [0, 1). Use 0 for a cohort","help_text": "Target \u0027delta\u0027 false positive rate in [0, 1). Use 0 for a cohort\nof samples which will be jointly analyzed for differential expression.\nA false positive is a true signal count that is erroneously removed.\nMore background removal is accompanied by more signal removal at\nhigh values of FPR. You can specify multiple values, which will\ncreate multiple output files.\n",
            "default": "[0.01]"
          },
          "exclude_feature_types": {
            "type": "string",
            "description": "Feature types to ignore during the analysis. These features will","help_text": "Feature types to ignore during the analysis. These features will\nbe left unchanged in the output file.\n",
            "default": ""
          },
          "projected_ambient_count_threshold": {
            "type": "number",
            "description": "Controls how many features are included in the analysis, which","help_text": "Controls how many features are included in the analysis, which\ncan lead to a large speedup. If a feature is expected to have less\nthan PROJECTED_AMBIENT_COUNT_THRESHOLD counts total in all cells\n(summed), then that gene is excluded, and it will be unchanged\nin the output count matrix. For example, \nPROJECTED_AMBIENT_COUNT_THRESHOLD = 0 will include all features\nwhich have even a single count in any empty droplet.\n",
            "default": "0.1"
          },
          "learning_rate": {
            "type": "number",
            "description": "Training detail: lower learning rate for inference.","help_text": "Training detail: lower learning rate for inference.\nA OneCycle learning rate schedule is used, where the\nupper learning rate is ten times this value. (For this\nvalue, probably do not exceed 1e-3).\n",
            "default": "0.0001"
          },
          "final_elbo_fail_fraction": {
            "type": "number",
            "description": "Training is considered to have failed if ","help_text": "Training is considered to have failed if \n(best_test_ELBO - final_test_ELBO)/(best_test_ELBO - initial_test_ELBO) \u003e FINAL_ELBO_FAIL_FRACTION.\nTraining will automatically re-run if --num-training-tries \u003e 1.\nBy default, will not fail training based on final_training_ELBO.\n",
            "default": ""
          },
          "epoch_elbo_fail_fraction": {
            "type": "number",
            "description": "Training is considered to have failed if ","help_text": "Training is considered to have failed if \n(previous_epoch_test_ELBO - current_epoch_test_ELBO)/(previous_epoch_test_ELBO - initial_train_ELBO) \u003e EPOCH_ELBO_FAIL_FRACTION.\nTraining will automatically re-run if --num-training-tries \u003e 1.\nBy default, will not fail training based on epoch_training_ELBO.\n",
            "default": ""
          },
          "num_training_tries": {
            "type": "integer",
            "description": "Number of times to attempt to train the model. At each subsequent attempt,","help_text": "Number of times to attempt to train the model. At each subsequent attempt,\nthe learning rate is multiplied by LEARNING_RATE_RETRY_MULT.\n",
            "default": "1"
          },
          "learning_rate_retry_mult": {
            "type": "number",
            "description": "Learning rate is multiplied by this amount each time a new training","help_text": "Learning rate is multiplied by this amount each time a new training\nattempt is made. (This parameter is only used if training fails based\non EPOCH_ELBO_FAIL_FRACTION or FINAL_ELBO_FAIL_FRACTION and\nNUM_TRAINING_TRIES is \u003e 1.) \n",
            "default": "0.2"
          },
          "posterior_batch_size": {
            "type": "integer",
            "description": "Training detail: size of batches when creating the posterior.","help_text": "Training detail: size of batches when creating the posterior.\nReduce this to avoid running out of GPU memory creating the posterior\n(will be slower).\n",
            "default": "128"
          },
          "posterior_regulation": {
            "type": "string",
            "description": "Posterior regularization method. (For experts: not required for normal usage,","help_text": "Posterior regularization method. (For experts: not required for normal usage,\nsee documentation). \n\n* PRq is approximate quantile-targeting.\n* PRmu is approximate mean-targeting aggregated over genes (behavior of v0.2.0).\n* PRmu_gene is approximate mean-targeting per gene.\n","enum": ["PRq", "PRmu", "PRmu_gene"],
            "default": ""
          },
          "alpha": {
            "type": "number",
            "description": "Tunable parameter alpha for the PRq posterior regularization method","help_text": "Tunable parameter alpha for the PRq posterior regularization method\n(not normally used: see documentation).\n",
            "default": ""
          },
          "q": {
            "type": "number",
            "description": "Tunable parameter q for the CDF threshold estimation method (not","help_text": "Tunable parameter q for the CDF threshold estimation method (not\nnormally used: see documentation).\n",
            "default": ""
          },
          "estimator": {
            "type": "string",
            "description": "Output denoised count estimation method. (For experts: not required","help_text": "Output denoised count estimation method. (For experts: not required\nfor normal usage, see documentation).\n","enum": ["map", "mean", "cdf", "sample", "mckp"],
            "default": "mckp"
          },
          "estimator_multiple_cpu": {
            "type": "boolean",
            "description": "Including the flag --estimator-multiple-cpu will use more than one","help_text": "Including the flag --estimator-multiple-cpu will use more than one\nCPU to compute the MCKP output count estimator in parallel (does nothing\nfor other estimators).\n",
            "default": "False"
          },
          "constant_learning_rate": {
            "type": "boolean",
            "description": "Including the flag --constant-learning-rate will use the ClippedAdam","help_text": "Including the flag --constant-learning-rate will use the ClippedAdam\noptimizer instead of the OneCycleLR learning rate schedule, which is\nthe default. Learning is faster with the OneCycleLR schedule.\nHowever, training can easily be continued from a checkpoint for more\nepochs than the initial command specified when using ClippedAdam. On\nthe other hand, if using the OneCycleLR schedule with 150 epochs\nspecified, it is not possible to pick up from that final checkpoint\nand continue training until 250 epochs.\n",
            "default": ""
          },
          "debug": {
            "type": "boolean",
            "description": "Including the flag --debug will log extra messages useful for debugging.","help_text": "Including the flag --debug will log extra messages useful for debugging.\n",
            "default": "False"
          },
          "cuda": {
            "type": "boolean",
            "description": "Including the flag --cuda will run the inference on a","help_text": "Including the flag --cuda will run the inference on a\nGPU.\n",
            "default": "False"
          }
          
        }
      },
      "nextflow input-output arguments" : {
        "title": "Nextflow input-output arguments",
        "type": "object",
        "description": "Input/output parameters for Nextflow itself. Please note that both publishDir and publish_dir are supported but at least one has to be configured.",
        "properties": {
          "publish_dir": {
            "type": "string",
            "description": "Path to an output directory.",
            "default": ""
          },
          "param_list": {
            "type": "string",
            "description": "Allows inputting multiple parameter sets to initialise a Nextflow channel. A `param_list` can either be a list of maps, a csv file, a json file, a yaml file, or simply a yaml blob.","help_text": "Allows inputting multiple parameter sets to initialise a Nextflow channel. A `param_list` can either be a list of maps, a csv file, a json file, a yaml file, or simply a yaml blob.\n\n* A list of maps (as-is) where the keys of each map corresponds to the arguments of the pipeline. Example: in a `nextflow.config` file: `param_list: [ [\u0027id\u0027: \u0027foo\u0027, \u0027input\u0027: \u0027foo.txt\u0027], [\u0027id\u0027: \u0027bar\u0027, \u0027input\u0027: \u0027bar.txt\u0027] ]`.\n* A csv file should have column names which correspond to the different arguments of this pipeline. Example: `--param_list data.csv` with columns `id,input`.\n* A json or a yaml file should be a list of maps, each of which has keys corresponding to the arguments of the pipeline. Example: `--param_list data.json` with contents `[ {\u0027id\u0027: \u0027foo\u0027, \u0027input\u0027: \u0027foo.txt\u0027}, {\u0027id\u0027: \u0027bar\u0027, \u0027input\u0027: \u0027bar.txt\u0027} ]`.\n* A yaml blob can also be passed directly as a string. Example: `--param_list \"[ {\u0027id\u0027: \u0027foo\u0027, \u0027input\u0027: \u0027foo.txt\u0027}, {\u0027id\u0027: \u0027bar\u0027, \u0027input\u0027: \u0027bar.txt\u0027} ]\"`.\n\nWhen passing a csv, json or yaml file, relative path names are relativized to the location of the parameter file. No relativation is performed when `param_list` is a list of maps (as-is) or a yaml blob.","hidden": true,
            "default": ""
          }
          
        }
      }
    },
    "allOf": [
      {
        "$ref": "#/definitions/inputs"
      },
      {
        "$ref": "#/definitions/outputs"
      },
      {
        "$ref": "#/definitions/arguments"
      },
      {
        "$ref": "#/definitions/nextflow input-output arguments"
      }
      ]
}
